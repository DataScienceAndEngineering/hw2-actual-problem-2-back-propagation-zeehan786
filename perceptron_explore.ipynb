{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2118c5",
   "metadata": {},
   "source": [
    "Import the required libraries (pandas, torch, seaborn and numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70bf3b",
   "metadata": {},
   "source": [
    "obtain the url for the dataset: 'https://bit.ly/palmerpenguinscsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbb0d0",
   "metadata": {},
   "source": [
    "read the dataset into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70599414",
   "metadata": {},
   "source": [
    "verify the successful creation of dataframe by printing the first five rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ad73a",
   "metadata": {},
   "source": [
    "get rid of all the rows where there are missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69816b4",
   "metadata": {},
   "source": [
    "check if there is any columns with existing null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a30525",
   "metadata": {},
   "source": [
    "seperate all the float type columns with the target variable i.e. species into a new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b3487",
   "metadata": {},
   "source": [
    "print the first five rows of the new dataframe for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053ebcf",
   "metadata": {},
   "source": [
    "use visualization tools to show features correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefa2cb",
   "metadata": {},
   "source": [
    "lets get rid of the value \"Chinstrap\" from the target variable and focus on binary classification:\n",
    "create a new dataframe from the numeric_df with no \"Chinstrap\" from the target variable. Verify by printing the different values of the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f520e8b",
   "metadata": {},
   "source": [
    "Also, reserve the feature variables to body mass and bill depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e13a2",
   "metadata": {},
   "source": [
    "lets get the tensor ready for training. Firstly, create a tensor consisting of only the dependent variables. Secondly, create a tensor for the independent variables where 1 represents Gentoo and 0 represents Adelie. \n",
    "Print the number of rows and the first 10 elements of the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d642b",
   "metadata": {},
   "source": [
    "Most algorithms will be sensitive to the order of the data. We will shuffle the data before we split it. We will use 20% of the data for validation.\n",
    "\n",
    "Create a random permutation of length = num of rows\n",
    "Create a variable pct_valid = 0.2 and use this for seperating the training and validation sets (X_train, y_train, X_test, y_test)\n",
    "print the total training examples and validation examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5023d1a",
   "metadata": {},
   "source": [
    "Standardize all the columns. Assuming the data is close to normally distributed this will keep the range of the input data between -3 and 3 and so it will be easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc76ba",
   "metadata": {},
   "source": [
    "Because we are working with Perceptrons to start, the preferred incoding is +1 for the positive class and -1 for the negative class. For logistic regression 0 and 1 would be better. It is important to know what is best encoding for the algorithm you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18514d1d",
   "metadata": {},
   "source": [
    "Since perceptron prefers +1 and -1 as the truth variables for binary problems, lets create a target tensor arrays with +1 and -1. Verify the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1afa6",
   "metadata": {},
   "source": [
    "initialize the weight vector witht the first element being the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79176adf",
   "metadata": {},
   "source": [
    "Create an activation function that returns 1 if the the variable z(dot product of weights and inputs) greater than or equal to 0 and -1 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bf704",
   "metadata": {},
   "source": [
    "Lets make a forward pass with the random set of weights and bias by creating the function model_predict(input_X, model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7794186",
   "metadata": {},
   "source": [
    "in the function model_predict use an assert statement to verify if the input data shape is of the same size as the model weight vector. Consequently, the X matrix is padded with 1s from the left side for the bias. Passed the dot product to the activation function and return from the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4e408",
   "metadata": {},
   "source": [
    "After implementing the model_predict function, the funciton is tested with training examples and validation examples. The output of the function is stored in the appropriate named variables and their shapes are printed to the screen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306c963",
   "metadata": {},
   "source": [
    "The simple cost function of the perceptron is implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1c322",
   "metadata": {},
   "source": [
    "Creating an accuracy function where the total number of correct predictions are calculated and the average is outputted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82c708",
   "metadata": {},
   "source": [
    "the accuracy of the random weights(with the bias) are printed out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f1d36",
   "metadata": {},
   "source": [
    "Everything is put together in a nested loop. The outer loop consist of the total epochs and the main work is being done inside the inner loop. In the inner loop, training data point is extracted at every iteration and fed into the model. The model output is used to calcuate the gradient and to generate the accuracy. If the predicted vector is same as the actual labels (a.k.a no errors), further progress of the inner loop is terminated by a continue statement and model begins training on subsequent data points. If no update has been made in an inner loop then this means the model has achieved either a local minima or global minima. Therefore, further training is terminated\n",
    "If the predicted vector is far from the actual labels, gradient is calculated to update the set of weights and the training continues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a1b62",
   "metadata": {},
   "source": [
    "repeat everything with Object Oriented Programming Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d0059",
   "metadata": {},
   "source": [
    "This time instead of removing Chinstrap, get rid of Adelie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39140a",
   "metadata": {},
   "source": [
    "create a class Perceptron, define an appropriate constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e96a03",
   "metadata": {},
   "source": [
    " implement the following methods: forward, update, accuracy, weight_delta, train, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1501b9d",
   "metadata": {},
   "source": [
    "initialize a model with random weights and print the trianing and validation accuracy. Consequently, trian the model and print the training and validation accuracyj. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
